{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.compat import urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 함수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(d):\n",
    "    d = d.lower()\n",
    "    d = re.sub(r'[a-z0-9\\-_.]{3,}@[a-z0-9\\-_.]{3,}(?:[.]?[a-z]{2})+', ' ', d)\n",
    "    d = re.sub(r'‘’ⓒ\\'\\\"“”…=□*◆:/_]', ' ', d)\n",
    "    d = re.sub(r'\\s+', ' ', d)\n",
    "    d = re.sub(r'^\\s|\\s$', '', d)\n",
    "    d = re.sub(r'[\\<br\\>]','',d)\n",
    "    d = re.sub(r'[<*>_=\"/]', '', d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base URL 설정\n",
    "\n",
    "### 페이지수를 볼 수 있는 네이버 뉴스 주소 (일반 뉴스는 .../main/main.naver?... 주소로 이루어짐)\n",
    "'https://news.naver.com/main/list.naver?\n",
    "\n",
    "mode=LSD&\n",
    "\n",
    "mid=shm&\n",
    "\n",
    "sid1=100&   -- 카테고리\n",
    "\n",
    "date={date}& -- 상세카테고리\n",
    "\n",
    "page={page}' -- 페이지\n",
    "\n",
    "\n",
    "sid1 (카테고리) : 100(정치), 101(경제), 102(사회), 103(생활문화), 104(세계), 105(IT과학), 106(연예), 107(스포츠), 110(오피니언)\n",
    "\n",
    "sid2 (상세카테고리) : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://news.naver.com/main/list.naver?mode=LSD&mid=shm&sid1=100&date={date}&page={page}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예외 단어 처리 - 재사용하기 위해 컴파일로 미리 저장.\n",
    "exclude_keywords = re.compile(r'(속보|포토)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 메타데이터 수집용 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 콘텐츠 (본문) 수집기 함수 정의\n",
    "# 작동 안 됨 -> 다음 단계에서 본문 전문 수집. \n",
    "# def fetch_article_content(article_url):\n",
    "#     resp = get(article_url)\n",
    "#     article_dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "#     content_tag = article_dom.select_one('div#articleBodyContents')\n",
    "#     if content_tag:\n",
    "#         return content_tag.get_text(strip=True)\n",
    "#     return ''\n",
    "\n",
    "# 기사 가져오는 함수\n",
    "def fetch_articles(url):\n",
    "    resp = get(url)\n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    articles = dom.select('.content ul.type06_headline li')\n",
    "    article_data_list = []\n",
    "\n",
    "    # DOM select로 얻어낸 html 반복문 실행하여 데이터 추출\n",
    "    for article in articles:\n",
    "        title_tag = article.find('dt', class_=None)\n",
    "        title_text = title_tag.get_text(strip=True)\n",
    "       \n",
    "        # 제목내 예외단어 발견시 추출 건너뛰기 (넘어가기)\n",
    "        if exclude_keywords.search(title_text):\n",
    "            continue\n",
    "    \n",
    "        # 기사 링크 태그, 주소, 요약 태그, 기자 태그\n",
    "        link_tag = title_tag.find('a')\n",
    "        article_url = link_tag['href']\n",
    "        summary_tag = article.find('span', class_='lede')\n",
    "        source_tag = article.find('span', class_='writing')\n",
    "        \n",
    "        # 기사 콘텐츠 (본문) 수집기\n",
    "        # content = fetch_article_content(article_url)\n",
    "\n",
    "        # 기사별 메타데이터 딕셔너리 생성\n",
    "        article_dict = {\n",
    "            'title': title_text,\n",
    "            'link': article_url,\n",
    "            'summary': summary_tag.get_text(strip=True) if summary_tag else '',\n",
    "            'source': source_tag.get_text(strip=True) if source_tag else '',\n",
    "            # 'content': content\n",
    "        }\n",
    "        \n",
    "        # 여러 기사에 대해 메타데이터 작성\n",
    "        article_data_list.append(article_dict)\n",
    "\n",
    "    return article_data_list, dom\n",
    "\n",
    "# 다음 페이지 넘어가기 : 최대 10페이지 전까지 정의\n",
    "def get_next_page(dom, current_page):\n",
    "    if current_page < 10:\n",
    "        next_page_tag = dom.select_one(f'.paging a[href*=\"page={current_page + 1}\"]')\n",
    "        if next_page_tag:\n",
    "            return urljoin(base_url, next_page_tag['href'])\n",
    "    return None\n",
    "\n",
    "# 일자별 크롤링 함수\n",
    "def generate_dates(start_date, end_date):\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        yield current_date\n",
    "        current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기사 메타데이터 (제목, 링크, 기자, 요약 등) 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:49, 24.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# 기사 수집 시작 / 종료 일자 (ex 2022-05-10: 2022년 5월 10일자)\n",
    "start_date = datetime.strptime('2024-04-23', '%Y-%m-%d')\n",
    "end_date = datetime.strptime('2024-04-24', '%Y-%m-%d')\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "for single_date in tqdm(generate_dates(start_date, end_date)):\n",
    "    date_str = single_date.strftime('%Y%m%d')\n",
    "    page = 1\n",
    "    url = base_url.format(date=date_str, page=page)\n",
    "    \n",
    "    while url and page <= 10:\n",
    "        article_data_list, dom = fetch_articles(url)\n",
    "        all_articles.extend(article_data_list)\n",
    "        url = get_next_page(dom, page)\n",
    "        page += 1\n",
    "        time.sleep(2)  # 서버에 부담을 주지 않도록 잠시 대기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기사 본문 전문 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 DataFrame 생성\n",
    "df1 = pd.DataFrame(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메타데이터 중복처리 & 백업\n",
    "df1.drop_duplicates(ignore_index=True)\n",
    "metadata_filename = f'메타데이터_{str(start_date)[:10]}_{str(end_date)[:10]}.csv'\n",
    "if df1.empty == 0:\n",
    "    df1.to_csv(f'./{metadata_filename}', index=False, encoding='utf-8-sig')\n",
    "print(f\"메타데이터 파일을 저장했습니다: {metadata_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 본문 (전문), 기자 정보 추출하기\n",
    "\n",
    "article_data_list = []\n",
    "\n",
    "def fetch_article_data(article_url):\n",
    "    resp = get(article_url)\n",
    "    article_dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    \n",
    "    # 기사 제목 추출\n",
    "    # title_tag = article_dom.select_one('h2#title_area')\n",
    "    # title = title_tag.get_text(strip=True) if title_tag else ''\n",
    "\n",
    "    # 기사 본문 추출\n",
    "    content_tag = article_dom.select_one('article')\n",
    "    content = preprocessing(content_tag.get_text(strip=True)) if content_tag else ''\n",
    "\n",
    "    # 언론사 정보 추출\n",
    "    # source_tag = article_dom.select_one('meta[property=\"og:article:author\"]')\n",
    "    # source = source_tag['content'] if source_tag else ''\n",
    "    \n",
    "    # 기자 정보 추출\n",
    "    reporter_tag = article_dom.select_one('div.byline span')\n",
    "    reporter = reporter_tag.get_text(strip=True) if reporter_tag else ''\n",
    "\n",
    "    article_data = {\n",
    "        # 'title': title,\n",
    "        'link': article_url,\n",
    "        'content': content,\n",
    "        # 'source': source,\n",
    "        'reporter': reporter\n",
    "    }\n",
    "\n",
    "    return article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [02:30<00:00,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "for url in tqdm(list(df1['link'])):\n",
    "    article_data = fetch_article_data(url)\n",
    "    article_data_list.append(article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(article_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터프레임 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 합치기\n",
    "df = pd.merge(df1, df2)\n",
    "\n",
    "# 데이터프레임 열 순서 바꾸기\n",
    "df = df[['source', 'reporter', 'title', 'summary', 'content', 'link']]\n",
    "\n",
    "# 중복 제거\n",
    "df.drop_duplicates(subset=None, keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "# 열 이름 변경\n",
    "df.columns = ['언론사', '기자', '제목', '기사요약', '기사전문', '기사링크']\n",
    "\n",
    "# 데이터프레임 형태 확인\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일로 저장되었습니다: 뉴스기사_2024-04-23_2024-04-24.csv\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일로 저장\n",
    "csv_filename = f'뉴스기사_{str(start_date)[:10]}_{str(end_date)[:10]}.csv'\n",
    "df.to_csv(f'./{csv_filename}', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"CSV 파일로 저장되었습니다: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정 언론사만 지정하여 라벨 남기기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select = df[(df['언론사']=='조선일보') | (df['언론사']=='중앙일보') | (df['언론사']=='동아일보') | (df['언론사']=='한겨레') | (df['언론사']=='경향신문') | (df['언론사']=='프레시안') | (df['언론사']=='오마이뉴스') | (df['언론사']=='문화일보')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\infer\\AppData\\Local\\Temp\\ipykernel_13412\\513145442.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_select['정치성향분류'] = [1 if x in ['한겨레', '경향신문', '프레시안', '오마이뉴스'] else 0 for x in df_select['언론사']]\n"
     ]
    }
   ],
   "source": [
    "# 0 : 보수 , 1 : 진보\n",
    "df_select['정치성향분류'] = [1 if x in ['한겨레', '경향신문', '프레시안', '오마이뉴스'] else 0 for x in df_select['언론사']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>언론사</th>\n",
       "      <th>기자</th>\n",
       "      <th>제목</th>\n",
       "      <th>기사요약</th>\n",
       "      <th>기사전문</th>\n",
       "      <th>기사링크</th>\n",
       "      <th>정치성향분류</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>중앙일보</td>\n",
       "      <td>정혜정 기자 jeong.hyejeong@joongang.co.kr</td>\n",
       "      <td>조국 \"尹정권 심판하란 민심 확인…쎈 구호만 외치고 빠지지 않아\"</td>\n",
       "      <td>조국 조국혁신당 대표는 23일 광주를 찾아 \"광주·전남 지역민이 보낸 지지는 우리 ...</td>\n",
       "      <td>조국 조국혁신당 대표가 23일 오후 광주 서구 김대중컨벤션센터에서 열린 '광주전남 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/025/000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>중앙일보</td>\n",
       "      <td>정혜정 기자 jeong.hyejeong@joongang.co.kr</td>\n",
       "      <td>권영세, 尹 오찬 거절한 한동훈에 \"韓이 잘못…맞추는 게 예의\"</td>\n",
       "      <td>권영세 국민의힘 의원은 23일 한동훈 전 국민의힘 비상대책위원장이 윤석열 대통령의 ...</td>\n",
       "      <td>윤석열 대통령이 지난 1월 29일 서울 용산 대통령실에서 한동훈 당시 국민의힘 비상...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/025/000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>조선일보</td>\n",
       "      <td>양지호 기자 yang.jiho@chosun.com</td>\n",
       "      <td>北 “핵 방아쇠”...계룡대 겨냥 ‘모의 핵탄두’ 장착해 시험 발사</td>\n",
       "      <td>북한은 22일 동해상으로 미사일 수 발을 발사한 것에 대해 “핵무기 종합 관리 체계...</td>\n",
       "      <td>북한이 지난 22일 김정은 국무위원장의 지도하에 핵 반격 가상 종합 전술 훈련을 실...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/023/000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>동아일보</td>\n",
       "      <td>김소영 동아닷컴 기자 sykim41@donga.com</td>\n",
       "      <td>용산 떠나는 이관섭…尹대통령, 직접 차 문 여닫으며 배웅</td>\n",
       "      <td>윤석열 대통령이 23일 대통령실을 떠나는 이관섭 전 대통령비서실장을 끝까지 배웅했다...</td>\n",
       "      <td>윤석열 대통령이 23일 오후 용산 대통령실 청사에서 열린 이관섭 전 비서실장 퇴임 ...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/020/000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>프레시안</td>\n",
       "      <td>박세열 기자(ilys123@pressian.com)</td>\n",
       "      <td>윤상현 \"대참패 책임은 한동훈…내 제안 들었다면 132석 했을 것\"</td>\n",
       "      <td>국민의힘의 수도권 참패 속 인천 동·미추홀을에서 당선된 윤상현 의원이 한동훈 전 비...</td>\n",
       "      <td>국민의힘의 수도권 참패 속 인천 동·미추홀을에서 당선된 윤상현 의원이 한동훈 전 비...</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/002/000...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     언론사                                    기자  \\\n",
       "3   중앙일보  정혜정 기자 jeong.hyejeong@joongang.co.kr   \n",
       "13  중앙일보  정혜정 기자 jeong.hyejeong@joongang.co.kr   \n",
       "21  조선일보           양지호 기자 yang.jiho@chosun.com   \n",
       "29  동아일보         김소영 동아닷컴 기자 sykim41@donga.com   \n",
       "41  프레시안          박세열 기자(ilys123@pressian.com)   \n",
       "\n",
       "                                       제목  \\\n",
       "3    조국 \"尹정권 심판하란 민심 확인…쎈 구호만 외치고 빠지지 않아\"   \n",
       "13    권영세, 尹 오찬 거절한 한동훈에 \"韓이 잘못…맞추는 게 예의\"   \n",
       "21  北 “핵 방아쇠”...계룡대 겨냥 ‘모의 핵탄두’ 장착해 시험 발사   \n",
       "29        용산 떠나는 이관섭…尹대통령, 직접 차 문 여닫으며 배웅   \n",
       "41  윤상현 \"대참패 책임은 한동훈…내 제안 들었다면 132석 했을 것\"   \n",
       "\n",
       "                                                 기사요약  \\\n",
       "3   조국 조국혁신당 대표는 23일 광주를 찾아 \"광주·전남 지역민이 보낸 지지는 우리 ...   \n",
       "13  권영세 국민의힘 의원은 23일 한동훈 전 국민의힘 비상대책위원장이 윤석열 대통령의 ...   \n",
       "21  북한은 22일 동해상으로 미사일 수 발을 발사한 것에 대해 “핵무기 종합 관리 체계...   \n",
       "29  윤석열 대통령이 23일 대통령실을 떠나는 이관섭 전 대통령비서실장을 끝까지 배웅했다...   \n",
       "41  국민의힘의 수도권 참패 속 인천 동·미추홀을에서 당선된 윤상현 의원이 한동훈 전 비...   \n",
       "\n",
       "                                                 기사전문  \\\n",
       "3   조국 조국혁신당 대표가 23일 오후 광주 서구 김대중컨벤션센터에서 열린 '광주전남 ...   \n",
       "13  윤석열 대통령이 지난 1월 29일 서울 용산 대통령실에서 한동훈 당시 국민의힘 비상...   \n",
       "21  북한이 지난 22일 김정은 국무위원장의 지도하에 핵 반격 가상 종합 전술 훈련을 실...   \n",
       "29  윤석열 대통령이 23일 오후 용산 대통령실 청사에서 열린 이관섭 전 비서실장 퇴임 ...   \n",
       "41  국민의힘의 수도권 참패 속 인천 동·미추홀을에서 당선된 윤상현 의원이 한동훈 전 비...   \n",
       "\n",
       "                                                 기사링크  정치성향분류  \n",
       "3   https://n.news.naver.com/mnews/article/025/000...       0  \n",
       "13  https://n.news.naver.com/mnews/article/025/000...       0  \n",
       "21  https://n.news.naver.com/mnews/article/023/000...       0  \n",
       "29  https://n.news.naver.com/mnews/article/020/000...       0  \n",
       "41  https://n.news.naver.com/mnews/article/002/000...       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_select.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ku-sw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
